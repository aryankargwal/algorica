# TanH
Another widely used Activation Function similar to the Sigmoid Activation Function having the same "S" shape but ranges from -1 to 1.<br><br>
<img src="https://www.medcalc.org/manual/_help/functions/tanh.png"><br><br>

### Advantages
- Zero Centered
- Smooth gradient, preventing “jumps” in output values.
- Output values bound between -1 and 1, normalizing the output of each neuron.
### Disadvantages
- Vanishing gradient—for very high or very low values of X, there is almost no change to the prediction, causing a vanishing gradient problem. 
- Compuationally Expensive